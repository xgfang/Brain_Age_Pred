{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# class MRIModalityDataset(Dataset):\n",
    "#     def __init__(self, root_dir, mmap_mode='r'):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.mmap_mode = mmap_mode\n",
    "#         self.files = sorted([\n",
    "#             f for f in os.listdir(root_dir) if f.endswith('.npy')\n",
    "#         ])\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.files)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         file_name = self.files[idx]\n",
    "#         path = os.path.join(self.root_dir, file_name)\n",
    "#         arr = np.load(path, mmap_mode=self.mmap_mode) \n",
    "#         arr = arr.squeeze(axis=0)                     \n",
    "#         tensor = torch.from_numpy(arr.astype(np.float32))\n",
    "#         return tensor\n",
    "\n",
    "\n",
    "class MRIModalityDataset(Dataset):\n",
    "    def __init__(self, npy_path, mmap_mode='r'):\n",
    "        self.data = np.load(npy_path, mmap_mode=mmap_mode)  # shape: (N, D, H, W)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]  # (121, 145, 121)\n",
    "        tensor = torch.from_numpy(img.astype(np.float32)).unsqueeze(0)  # -> (1, 121, 145, 121)\n",
    "        return tensor\n",
    "\n",
    "    \n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "class VBMEncoder3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, hidden_channels=16, latent_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2) # (121,145,121) -> (60,72,60)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(hidden_channels, hidden_channels * 2, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=2) # (60,72,60) -> (30,36,30)\n",
    "\n",
    "        # Final shape: (30, 36, 30)\n",
    "        self.feature_shape = (hidden_channels * 2, 30, 36, 30)\n",
    "        self.flat_dim = torch.prod(torch.tensor(self.feature_shape)).item()\n",
    "\n",
    "        self.fc_mu = nn.Linear(self.flat_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.flat_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "class VBMDecoder3D(nn.Module):\n",
    "    def __init__(self, out_channels=1, hidden_channels=16, latent_dim=128, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.feature_shape = (hidden_channels * 2, 30, 36, 30)\n",
    "        self.flat_dim = torch.prod(torch.tensor(self.feature_shape)).item()\n",
    "\n",
    "        self.fc = nn.Linear(latent_dim, self.flat_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose3d(hidden_channels * 2, hidden_channels, kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.Conv3d(hidden_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.deconv2 = nn.ConvTranspose3d(\n",
    "            hidden_channels, out_channels, kernel_size=2, stride=2, output_padding=(1, 1, 1)\n",
    "        )\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(z.size(0), *self.feature_shape)\n",
    "\n",
    "        x = self.deconv1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.deconv2(x)\n",
    "        x = self.conv2(x) \n",
    "\n",
    "        return x\n",
    "\n",
    "class VAEVBM3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, hidden_channels=16, latent_dim=128, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.encoder = VBMEncoder3D(in_channels, hidden_channels, latent_dim)\n",
    "        self.decoder = VBMDecoder3D(out_channels, hidden_channels, latent_dim, dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        recon = self.decoder(z)\n",
    "        return recon, mu, logvar\n",
    "\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar, beta=1.0):\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + beta * kld, recon_loss.item(), kld.item()\n",
    "\n",
    "\n",
    "def train_vae(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    lr=1e-4,\n",
    "    device='cuda',\n",
    "    beta=1.0,\n",
    "    patience=5,\n",
    "    min_delta=0.0,\n",
    "    max_epochs=100\n",
    "):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    n_train = len(train_loader.dataset)\n",
    "    n_val = len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Number of training samples: {n_train}\")\n",
    "    print(f\"Number of validation samples: {n_val}\\n\")\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            recon, mu, logvar = model(batch_data)\n",
    "            loss, _, _ = vae_loss(recon, batch_data, mu, logvar, beta)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_data in val_loader:\n",
    "                batch_data = batch_data.to(device)\n",
    "                recon, mu, logvar = model(batch_data)\n",
    "                loss, _, _ = vae_loss(recon, batch_data, mu, logvar, beta)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / n_train\n",
    "        avg_val_loss = total_val_loss / n_val\n",
    "\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss + min_delta < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"EarlyStopping counter: {epochs_no_improve} out of {patience}\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"\\nEarly stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a4748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_loss(train_loss_history, val_loss_history):\n",
    "    epochs = range(1, len(train_loss_history) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    \n",
    "    plt.plot(epochs, train_loss_history, label=\"Training Loss\", color=\"tab:blue\", linewidth=2)\n",
    "    plt.plot(epochs, val_loss_history, label=\"Validation Loss\", color=\"tab:orange\", linewidth=2, linestyle='--')\n",
    "\n",
    "    plt.xlabel(\"Epoch\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.title(\"VAE Training and Validation Loss Over Epochs\", fontsize=16)\n",
    "\n",
    "    plt.legend(fontsize=12)\n",
    "    \n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08502b7e",
   "metadata": {},
   "source": [
    "##### Use all VBM training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dfc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vbm_ds = MRIModalityDataset(\"features_3d_train_vbm.npy\")\n",
    "train_vbm_loader = DataLoader(train_vbm_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "val_vbm_ds = MRIModalityDataset(\"features_3d_val_vbm.npy\")\n",
    "val_vbm_loader = DataLoader(val_vbm_ds, batch_size=2, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vbm = VAEVBM3D(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    hidden_channels=16,\n",
    "    latent_dim=128, \n",
    "    dropout_rate=0.0\n",
    ").to(device)\n",
    "\n",
    "print(\"=== Training VBM VAE ===\")\n",
    "train_loss, val_loss = train_vae(model_vbm,\n",
    "                                 train_loader=train_vbm_loader,\n",
    "                                 val_loader=val_vbm_loader,\n",
    "                                 lr=1e-4,\n",
    "                                 device=device,\n",
    "                                 beta=1.0,\n",
    "                                 patience=5,      \n",
    "                                 min_delta=0.01,    \n",
    "                                 max_epochs=100   \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = np.array(train_loss)\n",
    "val_loss = np.array(val_loss)\n",
    "\n",
    "np.save(\"VAE_train_loss.npy\", train_loss)\n",
    "np.save(\"VAE_val_loss.npy\", val_loss)\n",
    "\n",
    "# train_loss = np.load(\"VAE_train_loss.npy\")\n",
    "# val_loss = np.load(\"VAE_val_loss.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e352e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_loss(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7445d23c",
   "metadata": {},
   "source": [
    "### Extracting Latent Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latents(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    all_latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in dataloader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            mu, _ = model.encoder(batch_data)\n",
    "            all_latents.append(mu.cpu())\n",
    "\n",
    "    return torch.cat(all_latents, dim=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training dataset\n",
    "train_feature_loader = DataLoader(train_vbm_ds, batch_size=2, shuffle=False)\n",
    "VBM_train_features = extract_latents(model_vbm, train_feature_loader, device=device)\n",
    "\n",
    "## validation dataset\n",
    "val_feature_loader = DataLoader(val_vbm_ds, batch_size=2, shuffle=False)\n",
    "VBM_val_features = extract_latents(model_vbm, val_feature_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(VBM_train_features.shape)\n",
    "print(VBM_val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a3dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'train': VBM_train_features,\n",
    "    'val': VBM_val_features\n",
    "}, 'vbm_features.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
